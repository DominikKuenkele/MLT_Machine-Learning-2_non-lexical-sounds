{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Imports/Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "SWB_DIR = os.path.join(DATA_DIR, 'swb_ms98_transcriptions/')\n",
    "\n",
    "SILENCE = '<silence>'\n",
    "NLS = [\n",
    "    'ah',\n",
    "    'eh', # pronouned 'eh'\n",
    "    'eh', # pronouned 'ey'\n",
    "    'hm',\n",
    "    'huh',\n",
    "    'huh-uh',\n",
    "    'hum-um',\n",
    "    'ooh',\n",
    "    'uh',\n",
    "    'uh-huh',\n",
    "    'uh-hum',\n",
    "    'uh-oh',\n",
    "    'um',\n",
    "    'um-hum',\n",
    "]\n",
    "\n",
    "PADDING_TOKEN = '<PAD>'\n",
    "UNKNOWN_TOKEN = '<UNK>'\n",
    "START_TOKEN = '<SOS>'\n",
    "END_TOKEN = '<EOS>'\n",
    "NO_NLS_TOKEN = '<NO-NLS>'\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400004, 300])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.vectors = torch.cat((glove_vectors.vectors, torch.rand(4, 300)))\n",
    "\n",
    "glove_vectors.itos.append(START_TOKEN)\n",
    "glove_vectors.stoi[START_TOKEN] = 400000\n",
    "glove_vectors.itos.append(END_TOKEN)\n",
    "glove_vectors.stoi[END_TOKEN] = 400001\n",
    "glove_vectors.itos.append(PADDING_TOKEN)\n",
    "glove_vectors.stoi[PADDING_TOKEN] = 400002\n",
    "glove_vectors.itos.append(UNKNOWN_TOKEN)\n",
    "glove_vectors.stoi[UNKNOWN_TOKEN] = 400002\n",
    "\n",
    "# for better performance\n",
    "glove_vocab = set(glove_vectors.itos)\n",
    "glove_vectors.vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'batch_size': 64,\n",
    "    'embedding_dim': 512,\n",
    "    'lstm_out_dim': 350,\n",
    "    'dropout_prob': 0.2,\n",
    "    'epochs': 20,\n",
    "    'glove_training_epoch': 10,\n",
    "    'learning_rate': 0.002\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UtteranceCollector():\n",
    "    ANNOTATIONS = [\n",
    "        #     r'\\[silence\\]', # may be also a sign of hesitation\n",
    "        r'\\[noise\\]',\n",
    "        r'\\[laughter\\]',\n",
    "        r'\\[vocalized-noise\\]'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, path, max_number_files=-1) -> None:\n",
    "        # nlp = English()\n",
    "        # nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "        self.utterances = []\n",
    "        for file_index, filename in enumerate(glob.iglob(os.path.join(path + '**/*trans*'), recursive=True)):\n",
    "            if file_index == max_number_files:\n",
    "                break\n",
    "\n",
    "            folders = filename.split('/')\n",
    "            dialogue_id = folders[-2]\n",
    "            dialogue_partner = folders[-1][folders[-1].find(dialogue_id) + len(dialogue_id)]\n",
    "\n",
    "            with open(filename, 'r') as f:\n",
    "                saved_utterances = []\n",
    "                for line in f:\n",
    "                    utterance = self.cleanse_utterance(line)\n",
    "                    if utterance != SILENCE and utterance != '':\n",
    "                        self.utterances.append({\n",
    "                                'dialogue_id': dialogue_id,\n",
    "                                'dialogue_partner': dialogue_partner,\n",
    "                                'utterance': utterance\n",
    "                            })\n",
    "                    # if utterance == SILENCE and len(saved_utterances) != 0:\n",
    "                    #     # doc = nlp(' '.join(saved_utterances))\n",
    "                    #     # for sentence in doc.sents:\n",
    "                    #     #     utterances.append({\n",
    "                    #     #         'dialogue_id': dialogue_id,\n",
    "                    #     #         'dialoge_partner': dialogue_partner,\n",
    "                    #     #         'utterance': sentence.text\n",
    "                    #     #     })\n",
    "                    #     self.utterances.append({\n",
    "                    #             'dialogue_id': dialogue_id,\n",
    "                    #             'dialogue_partner': dialogue_partner,\n",
    "                    #             'utterance': ' '.join(saved_utterances)\n",
    "                    #         })\n",
    "                    #     saved_utterances = []\n",
    "\n",
    "                    # elif utterance != '' and utterance != SILENCE:\n",
    "                    #     saved_utterances.append(utterance)\n",
    "\n",
    "    def cleanse_utterance(self, utterance: str):\n",
    "        utterance = utterance.rstrip().split(' ', maxsplit=3)[-1]\n",
    "\n",
    "        # remove annotations\n",
    "        utterance = re.sub(fr'({\"|\".join(self.ANNOTATIONS)})', '', utterance)\n",
    "\n",
    "        # replace anomalous words.\n",
    "        # E.g.: \"... [bettle/better] ...\" -> \"... better ...\".\n",
    "        # Also prevent duplications: \"... [bettle/better] better ...\" -> \"... better ...\"\n",
    "        utterance = re.sub(r\"(^| )\\[(.*?)\\/(?P<replace>.*?)\\]( (?P=replace))?( |$|-)\", lambda x: f' {x.group(3)} ', utterance)\n",
    "\n",
    "        # replace words containing laughter.\n",
    "        # E.g.: \"... [laughter-alone] ...\" -> \"... alone ...\"\n",
    "        utterance = re.sub(r\"(^| )\\[laughter-(.*?)\\]( |$|-)\", lambda x: f' {x.group(2)} ', utterance)\n",
    "\n",
    "        # exclude too complicated annotations to replace automatically\n",
    "        if utterance.find(' [') > -1:\n",
    "            return ''\n",
    "        \n",
    "        # replace partial word pronounciations\n",
    "        # E.g. \"... pla[stic]- ...\" -> \"... plastic- ...\"\n",
    "        utterance = re.sub(r'\\[silence\\]', SILENCE, utterance)\n",
    "        utterance = re.sub(r'(\\[|\\])', '', utterance)\n",
    "\n",
    "        # remove duplicate blanks\n",
    "        utterance = re.sub(r' +', ' ', utterance).strip()\n",
    "\n",
    "        return utterance   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_nls(utterance: str):\n",
    "    return any(nls in utterance['utterance'] for nls in [*NLS, SILENCE])\n",
    "\n",
    "def contains_repetition(utterance: str, ngram=1):\n",
    "    split_utterance = utterance['utterance'].split(' ')\n",
    "    # include partial word pronounciations\n",
    "    split_utterance = [word.rstrip('-') for word in split_utterance]\n",
    "    zipped = list(zip(*[split_utterance[i:] for i in range(ngram)]))\n",
    "    return any(zipped[index] == zipped[index - ngram] for index in range(ngram, len(zipped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 247123\n",
      "contain nls: 135287\n",
      "contain 1-gram repetitions: 47199\n",
      "\t-> well tell me what what do you think of uh of the current trends of how other people spend time with their children and so forth\n",
      "contain 2-gram repetitions: 9994\n",
      "\t-> you know because they don't they don't wanna send them to day care\n",
      "contain 3-gram repetitions: 1823\n",
      "\t-> so well keep up the good work and i'm going to i'm going to\n",
      "contain 4-gram repetitions: 428\n",
      "\t-> i guess in a perfect world in a perfect world uh but we aren't in a perfect world so i don't know\n",
      "contain 5-gram repetitions: 100\n",
      "\t-> upper body strength the easier it is to play you you have to do a you have to do a whole lot of sit ups and uh\n",
      "contain 6-gram repetitions: 21\n",
      "\t-> that uh that's a powerful force once you that's a powerful force once you learn something you you tend to wanna stick with it\n",
      "contain 7-gram repetitions: 9\n",
      "\t-> oh gosh yeah how do you usually cook your deer how do you usually cook your deer\n",
      "contain 8-gram repetitions: 5\n",
      "\t-> yeah i had to drive to the store yeah i had to drive to the store with paper towels all over my hands to go buy some paint thinner and right back and everything like that and then um\n",
      "contain 9-gram repetitions: 3\n",
      "\t-> each- each- each child is an individual and uh to be treated at a very very early age as a math and say you have to do this at a certain time you have to do this at a certain time it just wasn't working out real well\n",
      "Lengths:\n",
      "1: 64367 46093 46093 0\n",
      "2: 17871 10916 8235 2681\n",
      "3: 10264 4279 3483 796\n",
      "4: 8196 3462 2844 618\n",
      "5: 7589 3218 2585 633\n",
      "6: 7241 3267 2505 762\n",
      "7: 6982 3277 2447 830\n",
      "8: 6633 3377 2437 940\n",
      "9: 6371 3488 2515 973\n",
      "10: 5954 3522 2486 1036\n",
      "11: 5707 3674 2539 1135\n",
      "12: 5494 3645 2484 1161\n",
      "13: 5305 3684 2509 1175\n",
      "14: 4973 3667 2447 1220\n",
      "15: 4888 3669 2432 1237\n",
      "16: 4570 3566 2282 1284\n",
      "17: 4349 3521 2279 1242\n",
      "18: 4254 3407 2181 1226\n",
      "19: 3956 3391 2131 1260\n",
      "20: 3856 3411 2118 1293\n",
      "21: 3824 3440 2145 1295\n",
      "22: 3548 3227 1980 1247\n",
      "23: 3356 3171 1948 1223\n",
      "24: 3244 3124 1903 1221\n",
      "25: 3126 3094 1871 1223\n",
      "26: 2944 2970 1790 1180\n",
      "27: 2965 3034 1808 1226\n",
      "28: 2809 2897 1732 1165\n",
      "29: 2634 2730 1637 1093\n",
      "30: 2431 2601 1517 1084\n",
      "31: 2297 2524 1451 1073\n",
      "32: 2263 2477 1460 1017\n",
      "33: 2049 2284 1315 969\n",
      "34: 1978 2224 1293 931\n",
      "35: 1776 1977 1139 838\n",
      "36: 1682 1909 1099 810\n",
      "37: 1588 1833 1069 764\n",
      "38: 1592 1830 1033 797\n",
      "39: 1339 1588 912 676\n",
      "40: 1246 1511 856 655\n",
      "41: 1204 1459 796 663\n",
      "42: 1060 1260 718 542\n",
      "43: 982 1173 681 492\n",
      "44: 923 1108 628 480\n",
      "45: 767 896 492 404\n",
      "46: 645 773 421 352\n",
      "47: 586 716 377 339\n",
      "48: 560 677 362 315\n",
      "49: 446 558 300 258\n",
      "50: 379 459 251 208\n",
      "51: 364 420 218 202\n",
      "52: 300 348 191 157\n",
      "53: 254 302 160 142\n",
      "54: 222 271 136 135\n",
      "55: 190 224 122 102\n",
      "56: 145 174 91 83\n",
      "57: 112 143 77 66\n",
      "58: 87 105 57 48\n",
      "59: 84 97 46 51\n",
      "60: 73 94 50 44\n",
      "61: 51 64 31 33\n",
      "62: 39 38 19 19\n",
      "63: 30 37 21 16\n",
      "64: 28 28 13 15\n",
      "65: 19 19 9 10\n",
      "66: 22 22 10 12\n",
      "67: 7 8 3 5\n",
      "68: 8 7 4 3\n",
      "69: 6 7 4 3\n",
      "70: 4 4 3 1\n",
      "71: 1 1 0 1\n",
      "72: 2 2 2 0\n",
      "73: 2 2 0 2\n",
      "74: 4 4 2 2\n",
      "75: 1 1 0 1\n",
      "76: 2 2 1 1\n",
      "77: 1 1 0 1\n",
      "79: 1 2 1 1\n",
      "81: 1 1 0 1\n"
     ]
    }
   ],
   "source": [
    "utterances = UtteranceCollector(SWB_DIR).utterances\n",
    "\n",
    "print('Total:', len(utterances))\n",
    "\n",
    "contain_nls = list(filter(lambda x: contains_nls(x), utterances))\n",
    "print('contain nls:', len(contain_nls))\n",
    "\n",
    "for repetitions in range(1, 10):\n",
    "    contain_repetition = list(filter(lambda x: contains_repetition(x, repetitions), utterances))\n",
    "    print(f'contain {repetitions}-gram repetitions:', len(contain_repetition))\n",
    "    print('\\t->', random.choice(contain_repetition)['utterance'])\n",
    "\n",
    "print('Lengths:')\n",
    "lengths = {}\n",
    "for utterance in utterances:\n",
    "    utterance_length = len(utterance['utterance'].split(' '))\n",
    "    lengths.setdefault(utterance_length, []).append(utterance)\n",
    "for length, utts in sorted(lengths.items()):\n",
    "    contain_nls = list(filter(lambda x: contains_nls(x), utts))\n",
    "    contain_repetition = list(filter(lambda x: contains_repetition(x), utts))\n",
    "    print(f'{length}:', len(utts), len(contain_nls) + len(contain_repetition), len(contain_nls), len(contain_repetition))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(source_path, target_path_train, target_path_test, number_files=-1, train_split=0.8):\n",
    "    max_length_utterance = -1\n",
    "    \n",
    "    utterances = UtteranceCollector(source_path, number_files).utterances\n",
    "\n",
    "    delimiter = int(len(utterances) * train_split)\n",
    "\n",
    "    with open(target_path_train, 'w') as target_train:\n",
    "        for utterance in utterances[:delimiter]:\n",
    "            tokenized = nltk.word_tokenize(utterance['utterance'])\n",
    "            max_length_utterance = max(max_length_utterance, len(tokenized))\n",
    "            target_train.write(f\"{utterance['utterance']}\\t{utterance['dialogue_id']}\\t{utterance['dialogue_partner']}\\n\")\n",
    "    with open(target_path_test, 'w') as target_test:\n",
    "        for utterance in utterances[delimiter:]:\n",
    "            tokenized = nltk.word_tokenize(utterance['utterance'])\n",
    "            max_length_utterance = max(max_length_utterance, len(tokenized))\n",
    "            target_test.write(f\"{utterance['utterance']}\\t{utterance['dialogue_id']}\\t{utterance['dialogue_partner']}\\n\")\n",
    "\n",
    "    return max_length_utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_20.tsv'), os.path.join(DATA_DIR, 'test_20.tsv'), number_files=20)\n",
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_100.tsv'), os.path.join(DATA_DIR, 'test_100.tsv'), number_files=100)\n",
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_500.tsv'), os.path.join(DATA_DIR, 'test_500.tsv'), number_files=500)\n",
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_1000.tsv'), os.path.join(DATA_DIR, 'test_1000.tsv'), number_files=1000)\n",
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_all.tsv'), os.path.join(DATA_DIR, 'test_all.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLSDataset(Dataset):\n",
    "    def __init__(self, path, min_length_utterance=1, dataset=None, exclude_no_nls=False) -> None:\n",
    "        super().__init__()\n",
    "        utterances = self._read_file(path)\n",
    "\n",
    "        if dataset is None:\n",
    "            source_vocab = {UNKNOWN_TOKEN, START_TOKEN, END_TOKEN}\n",
    "            pos_vocab = {UNKNOWN_TOKEN, START_TOKEN, END_TOKEN}\n",
    "            for utterance in utterances:\n",
    "                tokenized = nltk.word_tokenize(utterance['utterance'])\n",
    "                filtered = [word for word in tokenized if word not in NLS]\n",
    "                pos_tagged = nltk.pos_tag(filtered)\n",
    "\n",
    "                source_vocab.update(filtered)\n",
    "                pos_vocab.update([tag[1] for tag in pos_tagged])\n",
    "\n",
    "            # PADDING_TOKEN will have index 0\n",
    "            self.vocab = {word: index for index, word in enumerate([PADDING_TOKEN, *list(source_vocab)])}\n",
    "            self.nls_vocab = {nls: index for index, nls in enumerate([PADDING_TOKEN, *list({*NLS, NO_NLS_TOKEN})])}\n",
    "            self.pos_vocab = {pos: index for index, pos in enumerate([PADDING_TOKEN, *list(pos_vocab)])}\n",
    "        else:\n",
    "            self.vocab = dataset.vocab\n",
    "            self.nls_vocab = dataset.nls_vocab\n",
    "            self.pos_vocab = dataset.pos_vocab\n",
    "\n",
    "        self.samples = []\n",
    "        for utterance in utterances:\n",
    "            tokenized = nltk.word_tokenize(utterance['utterance'])\n",
    "\n",
    "            if len(tokenized) >= min_length_utterance:\n",
    "                if exclude_no_nls and not any(nls in tokenized for nls in NLS):\n",
    "                    continue\n",
    "\n",
    "                tokenized.insert(0, START_TOKEN)\n",
    "                tokenized.append(END_TOKEN)\n",
    "\n",
    "                source_utterance = []\n",
    "                nls_predictions = []\n",
    "                for word in tokenized:\n",
    "                    if word not in NLS:\n",
    "                        source_utterance.append(word)\n",
    "                        nls_predictions.append(NO_NLS_TOKEN)\n",
    "                    else:\n",
    "                        nls_predictions[-1] = word\n",
    "\n",
    "                pos_tagged = nltk.pos_tag(source_utterance[1:-1])\n",
    "                pos_tags = [START_TOKEN, *[tag[1] for tag in pos_tagged], END_TOKEN]\n",
    "                \n",
    "                encoded_glove = [glove_vectors.stoi[word] if word in glove_vocab else glove_vectors.stoi[UNKNOWN_TOKEN] for word in source_utterance]\n",
    "                encoded_pos = [self.get_encoded_pos(pos) for pos in pos_tags]\n",
    "                encoded_source_utterance = [self.get_encoded_word(word) for word in source_utterance]\n",
    "                encoded_nls_predictions = [self.get_encoded_nls(nls) for nls in nls_predictions]\n",
    "                \n",
    "                self.samples.append({\n",
    "                    'dialogue_id': utterance['dialogue_id'],\n",
    "                    'dialogue_partner': utterance['dialogue_partner'],\n",
    "                    'utterance': utterance['utterance'],\n",
    "                    'tokenized_utterance': tokenized,\n",
    "                    'tokenized_utterance_without_nls': source_utterance,\n",
    "                    'pos_tags': pos_tags,\n",
    "                    'glove': torch.tensor(encoded_glove),\n",
    "                    'pos': torch.tensor(encoded_pos),\n",
    "                    'source': torch.tensor(encoded_source_utterance),\n",
    "                    'nls': torch.tensor(encoded_nls_predictions),\n",
    "                })\n",
    "\n",
    "    def _read_file(self, path):\n",
    "        utterances = []\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                utterance, dialogue_id, dialogue_partner = line.rstrip().split('\\t')\n",
    "                utterances.append({\n",
    "                    'utterance': utterance,\n",
    "                    'dialogue_id': dialogue_id,\n",
    "                    'dialogue_partner': dialogue_partner\n",
    "                })\n",
    "        \n",
    "        return utterances\n",
    "\n",
    "    def get_encoded_word(self, word) -> int:\n",
    "        if word in self.vocab:\n",
    "            return self.vocab[word]\n",
    "        else:\n",
    "            return self.vocab[UNKNOWN_TOKEN]\n",
    "    \n",
    "    def get_encoded_pos(self, pos) -> int:\n",
    "        if pos in self.pos_vocab:\n",
    "            return self.pos_vocab[pos]\n",
    "        else:\n",
    "            return self.pos_vocab[UNKNOWN_TOKEN]\n",
    "\n",
    "    def get_encoded_nls(self, nls) -> int:\n",
    "        return self.nls_vocab[nls]\n",
    "    \n",
    "    def get_nls_by_encoding(self, encoding) -> int:\n",
    "        mirrored_nls_vocab = {encoding: nls for nls, encoding in self.nls_vocab.items()}\n",
    "        return mirrored_nls_vocab[encoding]\n",
    "\n",
    "    def __getitem__(self, item) -> dict:\n",
    "        return self.samples[item]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_collate(data):\n",
    "    dialogue_ids = []\n",
    "    dialogue_partners = []\n",
    "    utterances = []\n",
    "    tokenized_utterances = []\n",
    "    tokenized_utterance_without_nls = []\n",
    "    pos_tags = []\n",
    "    glove = []\n",
    "    pos = []\n",
    "    source = []\n",
    "    nls = []\n",
    "    for sample in data:\n",
    "        dialogue_ids.append(sample['dialogue_id'])\n",
    "        dialogue_partners.append(sample['dialogue_id'])\n",
    "        utterances.append(sample['utterance'])\n",
    "        tokenized_utterances.append(sample['tokenized_utterance'])\n",
    "        tokenized_utterance_without_nls.append(sample['tokenized_utterance_without_nls'])\n",
    "        pos_tags.append(sample['pos_tags'])\n",
    "        glove.append(sample['glove'])\n",
    "        pos.append(sample['pos'])\n",
    "        source.append(sample['source'])\n",
    "        nls.append(sample['nls'])\n",
    "        \n",
    "    return {\n",
    "        'dialogue_ids': dialogue_ids,\n",
    "        'dialogue_partners': dialogue_partners,\n",
    "        'utterances': utterances,\n",
    "        'tokenized_utterances': tokenized_utterances,\n",
    "        'tokenized_utterance_without_nls': tokenized_utterance_without_nls,\n",
    "        'pos_tags': pos_tags,\n",
    "        'glove': pad_sequence(glove, batch_first=True, padding_value=glove_vectors.stoi[PADDING_TOKEN]),\n",
    "        'pos': pad_sequence(pos, batch_first=True),\n",
    "        'source': pad_sequence(source, batch_first=True),\n",
    "        'nls': pad_sequence(nls, batch_first=True)\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(path_train, path_test, batch_size):\n",
    "    train_dataset = NLSDataset(path_train, min_length_utterance=3)\n",
    "    test_dataset = NLSDataset(path_test, min_length_utterance=3, dataset=train_dataset)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  collate_fn=padding_collate)\n",
    "    test_dataloader = DataLoader(test_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 collate_fn=padding_collate)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = dataloader(os.path.join(DATA_DIR, 'train_all.tsv'), os.path.join(DATA_DIR, 'test_all.tsv'), hyperparameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133637"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2474"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.get_encoded_word(UNKNOWN_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue_id': '3763',\n",
       " 'dialogue_partner': 'B',\n",
       " 'utterance': \"that's contrary to uh popular belief you know\",\n",
       " 'tokenized_utterance': ['<SOS>',\n",
       "  'that',\n",
       "  \"'s\",\n",
       "  'contrary',\n",
       "  'to',\n",
       "  'uh',\n",
       "  'popular',\n",
       "  'belief',\n",
       "  'you',\n",
       "  'know',\n",
       "  '<EOS>'],\n",
       " 'tokenized_utterance_without_nls': ['<SOS>',\n",
       "  'that',\n",
       "  \"'s\",\n",
       "  'contrary',\n",
       "  'to',\n",
       "  'popular',\n",
       "  'belief',\n",
       "  'you',\n",
       "  'know',\n",
       "  '<EOS>'],\n",
       " 'pos_tags': ['<SOS>',\n",
       "  'DT',\n",
       "  'VBZ',\n",
       "  'JJ',\n",
       "  'TO',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'PRP',\n",
       "  'VBP',\n",
       "  '<EOS>'],\n",
       " 'glove': tensor([400000,     12,      9,   6605,      4,    814,   4440,     81,    346,\n",
       "         400001]),\n",
       " 'pos': tensor([30, 15, 13, 31, 28, 31,  8, 10, 16, 20]),\n",
       " 'source': tensor([ 8293, 26544, 15213, 11300,  4002, 12038,  1624, 27103,  3121,  9559]),\n",
       " 'nls': tensor([ 5,  5,  5,  5, 12,  5,  5,  5,  5,  5])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLSModel(nn.Module):\n",
    "    def __init__(self, vocab_size, pos_vocab_size, nls_vocab_size, embedding_dim, lstm_out_dim, padding_idx, dropout_prob, glove_vectors=None):\n",
    "        super(NLSModel, self).__init__()\n",
    "\n",
    "        if glove_vectors != None:\n",
    "            embedding_dim = glove_vectors.dim\n",
    "            self.word_embeddings = nn.Embedding.from_pretrained(glove_vectors.vectors, freeze=True, padding_idx=glove_vectors.stoi[PADDING_TOKEN])\n",
    "        else:\n",
    "            self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "\n",
    "        self.word_lstm = nn.LSTM(embedding_dim, lstm_out_dim, batch_first=True)\n",
    "\n",
    "        # self.pos_embeddings = nn.Embedding(pos_vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        # self.pos_lstm = nn.LSTM(embedding_dim, lstm_out_dim, batch_first=True)\n",
    "\n",
    "        # self.transformer_linear = nn.Linear(embedding_dim, 512)\n",
    "        # self.transformer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Linear(lstm_out_dim * 2, lstm_out_dim),\n",
    "            # nn.Dropout(dropout_prob),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(lstm_out_dim, int(lstm_out_dim/2)),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(lstm_out_dim/2), nls_vocab_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, source_sentence, source_pos):\n",
    "        word_embedding = self.word_embeddings(source_sentence)\n",
    "        word_dropped_out = self.dropout(word_embedding)\n",
    "        word_output, _ = self.word_lstm(word_dropped_out)\n",
    "\n",
    "        # pos_embedding = self.pos_embeddings(source_pos)\n",
    "        # pos_dropped_out = self.dropout(pos_embedding)\n",
    "        # pos_output, _ = self.pos_lstm(pos_dropped_out)\n",
    "\n",
    "        # transformed_linear = self.transformer_linear(word_embedding)\n",
    "        # transformed = self.transformer(transformed_linear)\n",
    "\n",
    "        predictions = self.classifier(word_output)\n",
    "        # predictions = self.classifier(torch.add(word_output, pos_output, alpha=0.5))\n",
    "        # predictions = self.classifier(torch.cat((word_output, pos_output), dim=2))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = CrossEntropyLoss(ignore_index=train_dataloader.dataset.get_encoded_nls(PADDING_TOKEN))\n",
    "nls_model = NLSModel(len(train_dataloader.dataset.vocab),\n",
    "                     len(train_dataloader.dataset.pos_vocab),\n",
    "                     len(train_dataloader.dataset.nls_vocab),\n",
    "                     hyperparameters['embedding_dim'],\n",
    "                     hyperparameters['lstm_out_dim'],\n",
    "                     train_dataloader.dataset.get_encoded_word(PADDING_TOKEN),\n",
    "                     hyperparameters['dropout_prob'],\n",
    "                     glove_vectors=glove_vectors)\n",
    "nls_model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(nls_model.parameters(), lr=hyperparameters['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nls(words, pos, tokenized_without_nls):\n",
    "    predicted = nls_model(words.to(device).unsqueeze(0), \n",
    "                          pos.to(device).unsqueeze(0))\n",
    "    argmax = torch.argmax(predicted.squeeze(0), dim=1)\n",
    "    decoded = [train_dataloader.dataset.get_nls_by_encoding(int(encoding)) for encoding in argmax]\n",
    "\n",
    "    target_sentence = []\n",
    "    for index, word in enumerate(tokenized_without_nls):\n",
    "        target_sentence.append(word)\n",
    "        if decoded[index] != NO_NLS_TOKEN:\n",
    "            target_sentence.append(decoded[index])\n",
    "            \n",
    "    return target_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'uh-hum', 'but', 'since-', 'uh-oh', 'you', 'uh', 'know', 'uh', 'since', 'hum-um', 'i', 'uh', 'live', 'uh', 'here', 'um', 'so', 'uh', 'close', 'uh', 'to', 'uh', 'Arlington', 'uh', '<EOS>', 'uh-oh']\n"
     ]
    }
   ],
   "source": [
    "source_sentence = train_dataloader.dataset[3]\n",
    "print('source:     ', source_sentence['tokenized_utterance_without_nls'])\n",
    "print('source_gold:', source_sentence['tokenized_utterance'])\n",
    "print('predicted:  ', predict_nls(source_sentence['glove'], source_sentence['pos'], source_sentence['tokenized_utterance_without_nls']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 EPOCHS - 2088 BATCHES PER EPOCH\n",
      "epoch 0, batch 2088: 0.1769\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 1, batch 2088: 0.1453\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 2, batch 2088: 0.1443\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 3, batch 2088: 0.1434\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 4, batch 2088: 0.1427\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 5, batch 2088: 0.1429\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 6, batch 2088: 0.1411\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 7, batch 2088: 0.1311\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 8, batch 2088: 0.1279\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 9, batch 2088: 0.1264\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 10, batch 2088: 0.1264\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 11, batch 2088: 0.1227\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 12, batch 2088: 0.1188\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 13, batch 2088: 0.1151\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 14, batch 2088: 0.1117\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 15, batch 2088: 0.1083\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 16, batch 2088: 0.1058\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 17, batch 2088: 0.1036\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 18, batch 2088: 0.1017\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 19, batch 2088: 0.1002\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "print(f'{hyperparameters[\"epochs\"]} EPOCHS - {math.floor(len(train_dataloader.dataset) / train_dataloader.batch_size)} BATCHES PER EPOCH')\n",
    "\n",
    "for epoch in range(hyperparameters['epochs']):\n",
    "    total_loss = 0\n",
    "\n",
    "    if epoch == hyperparameters['glove_training_epoch']:\n",
    "            nls_model.word_embeddings.weight.requires_grad = True\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        source = batch['glove'].to(device)\n",
    "        pos = batch['pos'].to(device)\n",
    "        nls = batch['nls'].to(device)\n",
    "\n",
    "        output = nls_model(source, pos)\n",
    "\n",
    "        loss = loss_function(output.permute(0, 2, 1), nls)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # print average loss for the epoch\n",
    "        sys.stdout.write(f'\\repoch {epoch}, batch {i}: {np.round(total_loss / (i + 1), 4)}')\n",
    "\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "    print()\n",
    "    print('source:     ', source_sentence['tokenized_utterance_without_nls'])\n",
    "    print('source_gold:', source_sentence['tokenized_utterance'])\n",
    "    print('predicted:  ', predict_nls(source_sentence['glove'], source_sentence['pos'], source_sentence['tokenized_utterance_without_nls']))\n",
    "\n",
    "del source, pos, nls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLSModel(\n",
       "  (word_embeddings): Embedding(400004, 300, padding_idx=400002)\n",
       "  (word_lstm): LSTM(300, 350, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=350, out_features=175, bias=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=175, out_features=15, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nls_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_nls = []\n",
    "gold_sentences = []\n",
    "\n",
    "predicted_nls = []\n",
    "predicted_sentences = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        source = batch['glove'].to(device)\n",
    "        pos = batch['pos'].to(device)\n",
    "\n",
    "        output = nls_model(source, pos)\n",
    "        argmax = torch.argmax(output, dim=2)\n",
    "        \n",
    "        predicted_nls.extend(argmax.tolist())\n",
    "        \n",
    "        \n",
    "        predicted_sentences.extend([predict_nls(glove, batch['pos'][index], batch['tokenized_utterance_without_nls'][index]) for index, glove in enumerate(batch['glove'])])\n",
    "\n",
    "        gold_nls.extend(batch['nls'].tolist())\n",
    "        gold_sentences.extend(batch['tokenized_utterances'])\n",
    "\n",
    "del source, pos    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "['<SOS>', 'you', 'know', 'and', 'once', 'a', 'week', 'we', 'drive', 'up', 'into', 'the', 'mountains', 'usually', 'you', 'know', 'usually', 'once', 'a', 'week', 'once', 'every', 'other', 'week', '<EOS>']\n",
      "['<SOS>', 'you', 'know', 'and', 'once', 'a', 'week', 'we', 'drive', 'up', 'into', 'the', 'mountains', 'usually', 'you', 'know', 'usually', 'once', 'a', 'week', 'once', 'every', 'other', 'week', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "print(gold_nls[0])\n",
    "print(predicted_nls[0])\n",
    "print(gold_sentences[0])\n",
    "print(predicted_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequences):\n",
    "    return [[test_dataloader.dataset.get_nls_by_encoding(encoding) for encoding in sequence] for sequence in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padding(gold, predicted):\n",
    "    unpadded_gold = [[token for token in sample if token != PADDING_TOKEN] for sample in gold]\n",
    "    unpadded_predicted = [sample[:len(unpadded_gold[index])] for index, sample in enumerate(predicted)]\n",
    "\n",
    "    return unpadded_gold, unpadded_predicted\n",
    "\n",
    "unpadded_gold_nls, unpadded_predicted_nls = remove_padding(decode(gold_nls), decode(predicted_nls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>']\n",
      "['<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>']\n"
     ]
    }
   ],
   "source": [
    "print(unpadded_gold_nls[0])\n",
    "print(unpadded_predicted_nls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of utterances, containing NLS:\n",
      "gold:      0.36797761261396805\n",
      "predicted: 0.0485962747871092\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of utterances, containing NLS:')\n",
    "print('gold:     ', sum([any(nls in sequence for nls in NLS) for sequence in unpadded_gold_nls]) / len(unpadded_gold_nls))\n",
    "print('predicted:', sum([any(nls in sequence for nls in NLS) for sequence in unpadded_predicted_nls]) / len(unpadded_predicted_nls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of NLS to <NO-NLS> in test set:\n",
      "NLS: 17167\n",
      "<NO-NLS>: 635201\n",
      "Ratio: 0.027\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of NLS to <NO-NLS> in test set:')\n",
    "\n",
    "number_nls = 0\n",
    "number_NO_NLS = 0\n",
    "for sequence in unpadded_gold_nls:\n",
    "    for word in sequence:\n",
    "        if word == NO_NLS_TOKEN:\n",
    "            number_NO_NLS += 1\n",
    "        else:\n",
    "            number_nls += 1\n",
    "\n",
    "nls_ratio = number_nls / number_NO_NLS\n",
    "\n",
    "print('NLS:', number_nls)\n",
    "print('<NO-NLS>:', number_NO_NLS)\n",
    "print('Ratio:', round(nls_ratio, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9665976223602545\n",
      "Average precision: 0.7846176930902309\n",
      "Average recall: 0.7981514587260463\n",
      "Average f1: 0.7907261100505186\n",
      "Average weighted accuracy: 0.02625035422924703\n",
      "NLS score: 0.49642398829475076\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "weighted_accuracies = []\n",
    "\n",
    "for index, sample in enumerate(unpadded_gold_nls):\n",
    "    predicted_sample = unpadded_predicted_nls[index]\n",
    "    accuracies.append(accuracy_score(sample, predicted_sample))\n",
    "    precisions.append(precision_score(sample, predicted_sample, average='macro', zero_division=0))\n",
    "    recalls.append(recall_score(sample, predicted_sample, average='macro', zero_division=0))\n",
    "    f1s.append(f1_score(sample, predicted_sample, average='macro', zero_division=0))\n",
    "    \n",
    "    weighted_accuracy = 0\n",
    "    for word_index, word in enumerate(sample):\n",
    "        if word == NO_NLS_TOKEN:\n",
    "            weight = nls_ratio\n",
    "        else:\n",
    "            weight = 1 - nls_ratio\n",
    "        \n",
    "        weighted_accuracy += weight * (word == predicted_sample[word_index])\n",
    "    weighted_accuracies.append(weighted_accuracy / len(sample))\n",
    "\n",
    "\n",
    "\n",
    "print('Average accuracy:', sum(accuracies) / len(accuracies))\n",
    "print('Average precision:', sum(precisions) / len(precisions))\n",
    "print('Average recall:', sum(recalls) / len(recalls))\n",
    "print('Average f1:', sum(f1s) / len(f1s))\n",
    "print('Average weighted accuracy:', sum(weighted_accuracies) / len(weighted_accuracies))\n",
    "print('NLS score:', ((sum(weighted_accuracies) / len(weighted_accuracies)) + (sum(accuracies) / len(accuracies))) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average meteor score: 0.9719289290194459\n"
     ]
    }
   ],
   "source": [
    "meteor_scores = [single_meteor_score(gold_sentence, predicted_sentences[index]) for index, gold_sentence in enumerate(gold_sentences)]\n",
    "print('Average meteor score:', sum(meteor_scores) / len(meteor_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'well', 'thank', 'you', 'very', 'much', 'bye-bye', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "def generate_nls_sentence(sentence):\n",
    "    tokenized = [START_TOKEN, *nltk.word_tokenize(sentence), END_TOKEN]\n",
    "    tagged = nltk.pos_tag(tokenized[1:-1])\n",
    "    pos_tagged = [START_TOKEN, *[tag[1] for tag in tagged], END_TOKEN]\n",
    "\n",
    "    pos_encoded = torch.Tensor([train_dataloader.dataset.get_encoded_pos(pos) for pos in pos_tagged]).type(torch.LongTensor)\n",
    "    glove_encoded = torch.Tensor([glove_vectors.stoi[word] if word in glove_vocab else glove_vectors.stoi[UNKNOWN_TOKEN] for word in tokenized]).type(torch.LongTensor)\n",
    "    word_encoded = torch.Tensor([train_dataloader.dataset.get_encoded_word(word) for word in tokenized]).type(torch.LongTensor)\n",
    "    \n",
    "    return predict_nls(glove_encoded, pos_encoded, tokenized)\n",
    "\n",
    "sentence = 'well thank you very much bye-bye'\n",
    "print(generate_nls_sentence(sentence))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('MLT_non-lexical')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb4abd3088b13a7e0c809898d81beb964403d8b7da59adbc39953b9d8f837bd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
