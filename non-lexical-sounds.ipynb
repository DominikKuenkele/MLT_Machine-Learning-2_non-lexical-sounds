{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Imports/Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import CrossEntropyLoss, KLDivLoss, NLLLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "SWB_DIR = os.path.join(DATA_DIR, 'swb_ms98_transcriptions/')\n",
    "\n",
    "SILENCE = '<silence>'\n",
    "NLS = [\n",
    "    'ah',\n",
    "    'eh', # pronouned 'eh'\n",
    "    'eh', # pronouned 'ey'\n",
    "    'hm',\n",
    "    'huh',\n",
    "    'huh-uh',\n",
    "    'hum-um',\n",
    "    'ooh',\n",
    "    'uh',\n",
    "    'uh-huh',\n",
    "    'uh-hum',\n",
    "    'uh-oh',\n",
    "    'um',\n",
    "    'um-hum',\n",
    "]\n",
    "\n",
    "PADDING_TOKEN = '<PAD>'\n",
    "UNKNOWN_TOKEN = '<UNK>'\n",
    "START_TOKEN = '<SOS>'\n",
    "END_TOKEN = '<EOS>'\n",
    "NO_NLS_TOKEN = '<NO-NLS>'\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400004, 300])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.vectors = torch.cat((glove_vectors.vectors, torch.rand(4, 300)))\n",
    "\n",
    "glove_vectors.itos.append(START_TOKEN)\n",
    "glove_vectors.stoi[START_TOKEN] = 400000\n",
    "glove_vectors.itos.append(END_TOKEN)\n",
    "glove_vectors.stoi[END_TOKEN] = 400001\n",
    "glove_vectors.itos.append(PADDING_TOKEN)\n",
    "glove_vectors.stoi[PADDING_TOKEN] = 400002\n",
    "glove_vectors.itos.append(UNKNOWN_TOKEN)\n",
    "glove_vectors.stoi[UNKNOWN_TOKEN] = 400002\n",
    "\n",
    "# for better performance\n",
    "glove_vocab = set(glove_vectors.itos)\n",
    "glove_vectors.vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'batch_size': 64,\n",
    "    'embedding_dim': 512,\n",
    "    'lstm_out_dim': 350,\n",
    "    'dropout_prob': 0.2,\n",
    "    'epochs': 20,\n",
    "    'glove_training_epoch': 10,\n",
    "    'learning_rate': 0.002\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UtteranceCollector():\n",
    "    ANNOTATIONS = [\n",
    "        #     r'\\[silence\\]', # may be also a sign of hesitation\n",
    "        r'\\[noise\\]',\n",
    "        r'\\[laughter\\]',\n",
    "        r'\\[vocalized-noise\\]'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, path, max_number_files=-1) -> None:\n",
    "        # nlp = English()\n",
    "        # nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "        self.utterances = []\n",
    "        for file_index, filename in enumerate(glob.iglob(os.path.join(path + '**/*trans*'), recursive=True)):\n",
    "            if file_index == max_number_files:\n",
    "                break\n",
    "\n",
    "            folders = filename.split('/')\n",
    "            dialogue_id = folders[-2]\n",
    "            dialogue_partner = folders[-1][folders[-1].find(dialogue_id) + len(dialogue_id)]\n",
    "\n",
    "            with open(filename, 'r') as f:\n",
    "                saved_utterances = []\n",
    "                for line in f:\n",
    "                    utterance = self.cleanse_utterance(line)\n",
    "                    if utterance != SILENCE and utterance != '':\n",
    "                        self.utterances.append({\n",
    "                                'dialogue_id': dialogue_id,\n",
    "                                'dialogue_partner': dialogue_partner,\n",
    "                                'utterance': utterance\n",
    "                            })\n",
    "                    # if utterance == SILENCE and len(saved_utterances) != 0:\n",
    "                    #     # doc = nlp(' '.join(saved_utterances))\n",
    "                    #     # for sentence in doc.sents:\n",
    "                    #     #     utterances.append({\n",
    "                    #     #         'dialogue_id': dialogue_id,\n",
    "                    #     #         'dialoge_partner': dialogue_partner,\n",
    "                    #     #         'utterance': sentence.text\n",
    "                    #     #     })\n",
    "                    #     self.utterances.append({\n",
    "                    #             'dialogue_id': dialogue_id,\n",
    "                    #             'dialogue_partner': dialogue_partner,\n",
    "                    #             'utterance': ' '.join(saved_utterances)\n",
    "                    #         })\n",
    "                    #     saved_utterances = []\n",
    "\n",
    "                    # elif utterance != '' and utterance != SILENCE:\n",
    "                    #     saved_utterances.append(utterance)\n",
    "\n",
    "    def cleanse_utterance(self, utterance: str):\n",
    "        utterance = utterance.rstrip().split(' ', maxsplit=3)[-1]\n",
    "\n",
    "        # remove annotations\n",
    "        utterance = re.sub(fr'({\"|\".join(self.ANNOTATIONS)})', '', utterance)\n",
    "\n",
    "        # replace anomalous words.\n",
    "        # E.g.: \"... [bettle/better] ...\" -> \"... better ...\".\n",
    "        # Also prevent duplications: \"... [bettle/better] better ...\" -> \"... better ...\"\n",
    "        utterance = re.sub(r\"(^| )\\[(.*?)\\/(?P<replace>.*?)\\]( (?P=replace))?( |$|-)\", lambda x: f' {x.group(3)} ', utterance)\n",
    "\n",
    "        # replace words containing laughter.\n",
    "        # E.g.: \"... [laughter-alone] ...\" -> \"... alone ...\"\n",
    "        utterance = re.sub(r\"(^| )\\[laughter-(.*?)\\]( |$|-)\", lambda x: f' {x.group(2)} ', utterance)\n",
    "\n",
    "        # exclude too complicated annotations to replace automatically\n",
    "        if utterance.find(' [') > -1:\n",
    "            return ''\n",
    "        \n",
    "        # replace partial word pronounciations\n",
    "        # E.g. \"... pla[stic]- ...\" -> \"... plastic- ...\"\n",
    "        utterance = re.sub(r'\\[silence\\]', SILENCE, utterance)\n",
    "        utterance = re.sub(r'(\\[|\\])', '', utterance)\n",
    "\n",
    "        # remove duplicate blanks\n",
    "        utterance = re.sub(r' +', ' ', utterance).strip()\n",
    "\n",
    "        return utterance   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_nls(utterance: str):\n",
    "    return any(nls in utterance['utterance'] for nls in [*NLS, SILENCE])\n",
    "\n",
    "def contains_repetition(utterance: str, ngram=1):\n",
    "    split_utterance = utterance['utterance'].split(' ')\n",
    "    # include partial word pronounciations\n",
    "    split_utterance = [word.rstrip('-') for word in split_utterance]\n",
    "    zipped = list(zip(*[split_utterance[i:] for i in range(ngram)]))\n",
    "    return any(zipped[index] == zipped[index - ngram] for index in range(ngram, len(zipped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SWB_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m utterances \u001b[39m=\u001b[39m UtteranceCollector(SWB_DIR)\u001b[39m.\u001b[39mutterances\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTotal:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(utterances))\n\u001b[1;32m      5\u001b[0m contain_nls \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m x: contains_nls(x), utterances))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SWB_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "utterances = UtteranceCollector(SWB_DIR).utterances\n",
    "\n",
    "print('Total:', len(utterances))\n",
    "\n",
    "contain_nls = list(filter(lambda x: contains_nls(x), utterances))\n",
    "print('contain nls:', len(contain_nls))\n",
    "\n",
    "for repetitions in range(1, 10):\n",
    "    contain_repetition = list(filter(lambda x: contains_repetition(x, repetitions), utterances))\n",
    "    print(f'contain {repetitions}-gram repetitions:', len(contain_repetition))\n",
    "    print('\\t->', random.choice(contain_repetition)['utterance'])\n",
    "\n",
    "print('Lengths:')\n",
    "lengths = {}\n",
    "for utterance in utterances:\n",
    "    utterance_length = len(utterance['utterance'].split(' '))\n",
    "    lengths.setdefault(utterance_length, []).append(utterance)\n",
    "for length, utts in sorted(lengths.items()):\n",
    "    contain_nls = list(filter(lambda x: contains_nls(x), utts))\n",
    "    contain_repetition = list(filter(lambda x: contains_repetition(x), utts))\n",
    "    print(f'{length}:', len(utts), len(contain_nls) + len(contain_repetition), len(contain_nls), len(contain_repetition))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(source_path, target_path_train, target_path_test, number_files=-1, train_split=0.8):\n",
    "    max_length_utterance = -1\n",
    "    \n",
    "    utterances = UtteranceCollector(source_path, number_files).utterances\n",
    "\n",
    "    delimiter = int(len(utterances) * train_split)\n",
    "\n",
    "    with open(target_path_train, 'w') as target_train:\n",
    "        for utterance in utterances[:delimiter]:\n",
    "            tokenized = nltk.word_tokenize(utterance['utterance'])\n",
    "            max_length_utterance = max(max_length_utterance, len(tokenized))\n",
    "            target_train.write(f\"{utterance['utterance']}\\t{utterance['dialogue_id']}\\t{utterance['dialogue_partner']}\\n\")\n",
    "    with open(target_path_test, 'w') as target_test:\n",
    "        for utterance in utterances[delimiter:]:\n",
    "            tokenized = nltk.word_tokenize(utterance['utterance'])\n",
    "            max_length_utterance = max(max_length_utterance, len(tokenized))\n",
    "            target_test.write(f\"{utterance['utterance']}\\t{utterance['dialogue_id']}\\t{utterance['dialogue_partner']}\\n\")\n",
    "\n",
    "    return max_length_utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_20.tsv'), os.path.join(DATA_DIR, 'test_20.tsv'), number_files=20)\n",
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_100.tsv'), os.path.join(DATA_DIR, 'test_100.tsv'), number_files=100)\n",
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_500.tsv'), os.path.join(DATA_DIR, 'test_500.tsv'), number_files=500)\n",
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_1000.tsv'), os.path.join(DATA_DIR, 'test_1000.tsv'), number_files=1000)\n",
    "split_data(SWB_DIR, os.path.join(DATA_DIR, 'train_all.tsv'), os.path.join(DATA_DIR, 'test_all.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLSDataset(Dataset):\n",
    "    def __init__(self, path, min_length_utterance=1, dataset=None, exclude_no_nls=False) -> None:\n",
    "        super().__init__()\n",
    "        utterances = self._read_file(path)\n",
    "\n",
    "        if dataset is None:\n",
    "            source_vocab = {UNKNOWN_TOKEN, START_TOKEN, END_TOKEN}\n",
    "            pos_vocab = {UNKNOWN_TOKEN, START_TOKEN, END_TOKEN}\n",
    "            for utterance in utterances:\n",
    "                tokenized = nltk.word_tokenize(utterance['utterance'])\n",
    "                filtered = [word for word in tokenized if word not in NLS]\n",
    "                pos_tagged = nltk.pos_tag(filtered)\n",
    "\n",
    "                source_vocab.update(filtered)\n",
    "                pos_vocab.update([tag[1] for tag in pos_tagged])\n",
    "\n",
    "            # PADDING_TOKEN will have index 0\n",
    "            self.vocab = {word: index for index, word in enumerate([PADDING_TOKEN, *list(source_vocab)])}\n",
    "            self.nls_vocab = {nls: index for index, nls in enumerate([PADDING_TOKEN, *list({*NLS, NO_NLS_TOKEN})])}\n",
    "            self.pos_vocab = {pos: index for index, pos in enumerate([PADDING_TOKEN, *list(pos_vocab)])}\n",
    "        else:\n",
    "            self.vocab = dataset.vocab\n",
    "            self.nls_vocab = dataset.nls_vocab\n",
    "            self.pos_vocab = dataset.pos_vocab\n",
    "\n",
    "        self.samples = []\n",
    "        for utterance in utterances:\n",
    "            tokenized = nltk.word_tokenize(utterance['utterance'])\n",
    "\n",
    "            if len(tokenized) >= min_length_utterance:\n",
    "                if exclude_no_nls and not any(nls in tokenized for nls in NLS):\n",
    "                    continue\n",
    "\n",
    "                tokenized.insert(0, START_TOKEN)\n",
    "                tokenized.append(END_TOKEN)\n",
    "\n",
    "                source_utterance = []\n",
    "                nls_predictions = []\n",
    "                for word in tokenized:\n",
    "                    if word not in NLS:\n",
    "                        source_utterance.append(word)\n",
    "                        nls_predictions.append(NO_NLS_TOKEN)\n",
    "                    else:\n",
    "                        nls_predictions[-1] = word\n",
    "\n",
    "                pos_tagged = nltk.pos_tag(source_utterance[1:-1])\n",
    "                pos_tags = [START_TOKEN, *[tag[1] for tag in pos_tagged], END_TOKEN]\n",
    "                \n",
    "                encoded_glove = [glove_vectors.stoi[word] if word in glove_vocab else glove_vectors.stoi[UNKNOWN_TOKEN] for word in source_utterance]\n",
    "                encoded_pos = [self.get_encoded_pos(pos) for pos in pos_tags]\n",
    "                encoded_source_utterance = [self.get_encoded_word(word) for word in source_utterance]\n",
    "                encoded_nls_predictions = [self.get_encoded_nls(nls) for nls in nls_predictions]\n",
    "                \n",
    "                self.samples.append({\n",
    "                    'dialogue_id': utterance['dialogue_id'],\n",
    "                    'dialogue_partner': utterance['dialogue_partner'],\n",
    "                    'utterance': utterance['utterance'],\n",
    "                    'tokenized_utterance': tokenized,\n",
    "                    'tokenized_utterance_without_nls': source_utterance,\n",
    "                    'pos_tags': pos_tags,\n",
    "                    'glove': torch.tensor(encoded_glove),\n",
    "                    'pos': torch.tensor(encoded_pos),\n",
    "                    'source': torch.tensor(encoded_source_utterance),\n",
    "                    'nls': torch.tensor(encoded_nls_predictions),\n",
    "                })\n",
    "\n",
    "    def _read_file(self, path):\n",
    "        utterances = []\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                utterance, dialogue_id, dialogue_partner = line.rstrip().split('\\t')\n",
    "                utterances.append({\n",
    "                    'utterance': utterance,\n",
    "                    'dialogue_id': dialogue_id,\n",
    "                    'dialogue_partner': dialogue_partner\n",
    "                })\n",
    "        \n",
    "        return utterances\n",
    "\n",
    "    def get_encoded_word(self, word) -> int:\n",
    "        if word in self.vocab:\n",
    "            return self.vocab[word]\n",
    "        else:\n",
    "            return self.vocab[UNKNOWN_TOKEN]\n",
    "    \n",
    "    def get_encoded_pos(self, pos) -> int:\n",
    "        if pos in self.pos_vocab:\n",
    "            return self.pos_vocab[pos]\n",
    "        else:\n",
    "            return self.pos_vocab[UNKNOWN_TOKEN]\n",
    "\n",
    "    def get_encoded_nls(self, nls) -> int:\n",
    "        return self.nls_vocab[nls]\n",
    "    \n",
    "    def get_nls_by_encoding(self, encoding) -> int:\n",
    "        mirrored_nls_vocab = {encoding: nls for nls, encoding in self.nls_vocab.items()}\n",
    "        return mirrored_nls_vocab[encoding]\n",
    "\n",
    "    def __getitem__(self, item) -> dict:\n",
    "        return self.samples[item]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_collate(data):\n",
    "    dialogue_ids = []\n",
    "    dialogue_partners = []\n",
    "    utterances = []\n",
    "    tokenized_utterances = []\n",
    "    tokenized_utterance_without_nls = []\n",
    "    pos_tags = []\n",
    "    glove = []\n",
    "    pos = []\n",
    "    source = []\n",
    "    nls = []\n",
    "    for sample in data:\n",
    "        dialogue_ids.append(sample['dialogue_id'])\n",
    "        dialogue_partners.append(sample['dialogue_id'])\n",
    "        utterances.append(sample['utterance'])\n",
    "        tokenized_utterances.append(sample['tokenized_utterance'])\n",
    "        tokenized_utterance_without_nls.append(sample['tokenized_utterance_without_nls'])\n",
    "        pos_tags.append(sample['pos_tags'])\n",
    "        glove.append(sample['glove'])\n",
    "        pos.append(sample['pos'])\n",
    "        source.append(sample['source'])\n",
    "        nls.append(sample['nls'])\n",
    "        \n",
    "    return {\n",
    "        'dialogue_ids': dialogue_ids,\n",
    "        'dialogue_partners': dialogue_partners,\n",
    "        'utterances': utterances,\n",
    "        'tokenized_utterances': tokenized_utterances,\n",
    "        'tokenized_utterance_without_nls': tokenized_utterance_without_nls,\n",
    "        'pos_tags': pos_tags,\n",
    "        'glove': pad_sequence(glove, batch_first=True, padding_value=glove_vectors.stoi[PADDING_TOKEN]),\n",
    "        'pos': pad_sequence(pos, batch_first=True),\n",
    "        'source': pad_sequence(source, batch_first=True),\n",
    "        'nls': pad_sequence(nls, batch_first=True)\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(path_train, path_test, batch_size):\n",
    "    train_dataset = NLSDataset(path_train, min_length_utterance=3)\n",
    "    test_dataset = NLSDataset(path_test, min_length_utterance=3, dataset=train_dataset)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  collate_fn=padding_collate)\n",
    "    test_dataloader = DataLoader(test_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 collate_fn=padding_collate)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = dataloader(os.path.join(DATA_DIR, 'train_all.tsv'), os.path.join(DATA_DIR, 'test_all.tsv'), hyperparameters['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133637"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11141"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.get_encoded_word(UNKNOWN_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue_id': '3763',\n",
       " 'dialogue_partner': 'B',\n",
       " 'utterance': \"that's contrary to uh popular belief you know\",\n",
       " 'tokenized_utterance': ['<SOS>',\n",
       "  'that',\n",
       "  \"'s\",\n",
       "  'contrary',\n",
       "  'to',\n",
       "  'uh',\n",
       "  'popular',\n",
       "  'belief',\n",
       "  'you',\n",
       "  'know',\n",
       "  '<EOS>'],\n",
       " 'tokenized_utterance_without_nls': ['<SOS>',\n",
       "  'that',\n",
       "  \"'s\",\n",
       "  'contrary',\n",
       "  'to',\n",
       "  'popular',\n",
       "  'belief',\n",
       "  'you',\n",
       "  'know',\n",
       "  '<EOS>'],\n",
       " 'pos_tags': ['<SOS>',\n",
       "  'DT',\n",
       "  'VBZ',\n",
       "  'JJ',\n",
       "  'TO',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'PRP',\n",
       "  'VBP',\n",
       "  '<EOS>'],\n",
       " 'glove': tensor([400000,     12,      9,   6605,      4,    814,   4440,     81,    346,\n",
       "         400001]),\n",
       " 'pos': tensor([ 3, 13,  4, 23, 35, 23, 20, 16, 39,  5]),\n",
       " 'source': tensor([ 1048, 23440, 28420, 20712,  9182, 20130,  9540, 11013, 18197, 23646]),\n",
       " 'nls': tensor([ 6,  6,  6,  6, 10,  6,  6,  6,  6,  6])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLSModel(nn.Module):\n",
    "    def __init__(self, vocab_size, pos_vocab_size, nls_vocab_size, embedding_dim, lstm_out_dim, padding_idx, dropout_prob, glove_vectors=None):\n",
    "        super(NLSModel, self).__init__()\n",
    "\n",
    "        if glove_vectors != None:\n",
    "            embedding_dim = glove_vectors.dim\n",
    "            self.word_embeddings = nn.Embedding.from_pretrained(glove_vectors.vectors, freeze=True, padding_idx=glove_vectors.stoi[PADDING_TOKEN])\n",
    "        else:\n",
    "            self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "\n",
    "        self.word_lstm = nn.LSTM(embedding_dim, lstm_out_dim, batch_first=True)\n",
    "\n",
    "        # self.pos_embeddings = nn.Embedding(pos_vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        # self.pos_lstm = nn.LSTM(embedding_dim, lstm_out_dim, batch_first=True)\n",
    "\n",
    "        # self.transformer_linear = nn.Linear(embedding_dim, 512)\n",
    "        # self.transformer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            # nn.Linear(lstm_out_dim * 2, lstm_out_dim),\n",
    "            # nn.Dropout(dropout_prob),\n",
    "            # nn.Tanh(),\n",
    "            nn.Linear(lstm_out_dim, int(lstm_out_dim/2)),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(lstm_out_dim/2), nls_vocab_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, source_sentence, source_pos):\n",
    "        word_embedding = self.word_embeddings(source_sentence)\n",
    "        word_dropped_out = self.dropout(word_embedding)\n",
    "        word_output, _ = self.word_lstm(word_dropped_out)\n",
    "\n",
    "        # pos_embedding = self.pos_embeddings(source_pos)\n",
    "        # pos_dropped_out = self.dropout(pos_embedding)\n",
    "        # pos_output, _ = self.pos_lstm(pos_dropped_out)\n",
    "\n",
    "        # transformed_linear = self.transformer_linear(word_embedding)\n",
    "        # transformed = self.transformer(transformed_linear)\n",
    "\n",
    "        predictions = self.classifier(word_output)\n",
    "        # predictions = self.classifier(torch.add(word_output, pos_output, alpha=0.5))\n",
    "        # predictions = self.classifier(torch.cat((word_output, pos_output), dim=2))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = CrossEntropyLoss(ignore_index=train_dataloader.dataset.get_encoded_nls(PADDING_TOKEN))\n",
    "nls_model = NLSModel(len(train_dataloader.dataset.vocab),\n",
    "                     len(train_dataloader.dataset.pos_vocab),\n",
    "                     len(train_dataloader.dataset.nls_vocab),\n",
    "                     hyperparameters['embedding_dim'],\n",
    "                     hyperparameters['lstm_out_dim'],\n",
    "                     train_dataloader.dataset.get_encoded_word(PADDING_TOKEN),\n",
    "                     hyperparameters['dropout_prob'],\n",
    "                     glove_vectors=glove_vectors)\n",
    "nls_model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(nls_model.parameters(), lr=hyperparameters['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nls(words, pos, tokenized_without_nls):\n",
    "    predicted = nls_model(words.to(device).unsqueeze(0), \n",
    "                          pos.to(device).unsqueeze(0))\n",
    "    argmax = torch.argmax(predicted.squeeze(0), dim=1)\n",
    "    decoded = [train_dataloader.dataset.get_nls_by_encoding(int(encoding)) for encoding in argmax]\n",
    "\n",
    "    target_sentence = []\n",
    "    for index, word in enumerate(tokenized_without_nls):\n",
    "        target_sentence.append(word)\n",
    "        if decoded[index] != NO_NLS_TOKEN:\n",
    "            target_sentence.append(decoded[index])\n",
    "            \n",
    "    return target_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'uh-hum', 'but', 'since-', 'uh-oh', 'you', 'uh', 'know', 'uh', 'since', 'hum-um', 'i', 'uh', 'live', 'uh', 'here', 'um', 'so', 'uh', 'close', 'uh', 'to', 'uh', 'Arlington', 'uh', '<EOS>', 'uh-oh']\n"
     ]
    }
   ],
   "source": [
    "source_sentence = train_dataloader.dataset[3]\n",
    "print('source:     ', source_sentence['tokenized_utterance_without_nls'])\n",
    "print('source_gold:', source_sentence['tokenized_utterance'])\n",
    "print('predicted:  ', predict_nls(source_sentence['glove'], source_sentence['pos'], source_sentence['tokenized_utterance_without_nls']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 EPOCHS - 2088 BATCHES PER EPOCH\n",
      "epoch 0, batch 2088: 0.1769\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 1, batch 2088: 0.1453\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 2, batch 2088: 0.1443\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 3, batch 2088: 0.1434\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 4, batch 2088: 0.1427\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 5, batch 2088: 0.1429\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 6, batch 2088: 0.1411\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 7, batch 2088: 0.1311\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 8, batch 2088: 0.1279\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 9, batch 2088: 0.1264\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 10, batch 2088: 0.1264\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 11, batch 2088: 0.1227\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 12, batch 2088: 0.1188\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 13, batch 2088: 0.1151\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 14, batch 2088: 0.1117\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 15, batch 2088: 0.1083\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 16, batch 2088: 0.1058\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 17, batch 2088: 0.1036\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 18, batch 2088: 0.1017\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "epoch 19, batch 2088: 0.1002\n",
      "source:      ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n",
      "source_gold: ['<SOS>', 'but', 'uh', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', 'uh', '<EOS>']\n",
      "predicted:   ['<SOS>', 'but', 'since-', 'you', 'know', 'since', 'i', 'live', 'here', 'so', 'close', 'to', 'Arlington', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "print(f'{hyperparameters[\"epochs\"]} EPOCHS - {math.floor(len(train_dataloader.dataset) / train_dataloader.batch_size)} BATCHES PER EPOCH')\n",
    "\n",
    "for epoch in range(hyperparameters['epochs']):\n",
    "    total_loss = 0\n",
    "\n",
    "    if epoch == hyperparameters['glove_training_epoch']:\n",
    "            nls_model.word_embeddings.weight.requires_grad = True\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        source = batch['glove'].to(device)\n",
    "        pos = batch['pos'].to(device)\n",
    "        nls = batch['nls'].to(device)\n",
    "\n",
    "        output = nls_model(source, pos)\n",
    "\n",
    "        loss = loss_function(output.permute(0, 2, 1), nls)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # print average loss for the epoch\n",
    "        sys.stdout.write(f'\\repoch {epoch}, batch {i}: {np.round(total_loss / (i + 1), 4)}')\n",
    "\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "    print()\n",
    "    print('source:     ', source_sentence['tokenized_utterance_without_nls'])\n",
    "    print('source_gold:', source_sentence['tokenized_utterance'])\n",
    "    print('predicted:  ', predict_nls(source_sentence['glove'], source_sentence['pos'], source_sentence['tokenized_utterance_without_nls']))\n",
    "\n",
    "del source, pos, nls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLSModel(\n",
       "  (word_embeddings): Embedding(400004, 300, padding_idx=400002)\n",
       "  (word_lstm): LSTM(300, 350, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=350, out_features=175, bias=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=175, out_features=15, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nls_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_nls = []\n",
    "gold_sentences = []\n",
    "\n",
    "predicted_nls = []\n",
    "predicted_sentences = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        source = batch['glove'].to(device)\n",
    "        pos = batch['pos'].to(device)\n",
    "\n",
    "        output = nls_model(source, pos)\n",
    "        argmax = torch.argmax(output, dim=2)\n",
    "        \n",
    "        predicted_nls.extend(argmax.tolist())\n",
    "        \n",
    "        \n",
    "        predicted_sentences.extend([predict_nls(glove, batch['pos'][index], batch['tokenized_utterance_without_nls'][index]) for index, glove in enumerate(batch['glove'])])\n",
    "\n",
    "        gold_nls.extend(batch['nls'].tolist())\n",
    "        gold_sentences.extend(batch['tokenized_utterances'])\n",
    "\n",
    "del source, pos    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "['<SOS>', 'you', 'know', 'and', 'once', 'a', 'week', 'we', 'drive', 'up', 'into', 'the', 'mountains', 'usually', 'you', 'know', 'usually', 'once', 'a', 'week', 'once', 'every', 'other', 'week', '<EOS>']\n",
      "['<SOS>', 'you', 'know', 'and', 'once', 'a', 'week', 'we', 'drive', 'up', 'into', 'the', 'mountains', 'usually', 'you', 'know', 'usually', 'once', 'a', 'week', 'once', 'every', 'other', 'week', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "print(gold_nls[0])\n",
    "print(predicted_nls[0])\n",
    "print(gold_sentences[0])\n",
    "print(predicted_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequences):\n",
    "    return [[test_dataloader.dataset.get_nls_by_encoding(encoding) for encoding in sequence] for sequence in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padding(gold, predicted):\n",
    "    unpadded_gold = [[token for token in sample if token != PADDING_TOKEN] for sample in gold]\n",
    "    unpadded_predicted = [sample[:len(unpadded_gold[index])] for index, sample in enumerate(predicted)]\n",
    "\n",
    "    return unpadded_gold, unpadded_predicted\n",
    "\n",
    "unpadded_gold_nls, unpadded_predicted_nls = remove_padding(decode(gold_nls), decode(predicted_nls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>']\n",
      "['<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>', '<NO-NLS>']\n"
     ]
    }
   ],
   "source": [
    "print(unpadded_gold_nls[0])\n",
    "print(unpadded_predicted_nls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of utterances, containing NLS:\n",
      "gold:      0.36797761261396805\n",
      "predicted: 0.0485962747871092\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of utterances, containing NLS:')\n",
    "print('gold:     ', sum([any(nls in sequence for nls in NLS) for sequence in unpadded_gold_nls]) / len(unpadded_gold_nls))\n",
    "print('predicted:', sum([any(nls in sequence for nls in NLS) for sequence in unpadded_predicted_nls]) / len(unpadded_predicted_nls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of NLS to <NO-NLS> in test set:\n",
      "NLS: 17167\n",
      "<NO-NLS>: 635201\n",
      "Ratio: 0.027\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of NLS to <NO-NLS> in test set:')\n",
    "\n",
    "number_nls = 0\n",
    "number_NO_NLS = 0\n",
    "for sequence in unpadded_gold_nls:\n",
    "    for word in sequence:\n",
    "        if word == NO_NLS_TOKEN:\n",
    "            number_NO_NLS += 1\n",
    "        else:\n",
    "            number_nls += 1\n",
    "\n",
    "nls_ratio = number_nls / number_NO_NLS\n",
    "\n",
    "print('NLS:', number_nls)\n",
    "print('<NO-NLS>:', number_NO_NLS)\n",
    "print('Ratio:', round(nls_ratio, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.9665976223602545\n",
      "Average precision: 0.7846176930902309\n",
      "Average recall: 0.7981514587260463\n",
      "Average f1: 0.7907261100505186\n",
      "Average weighted accuracy: 0.02625035422924703\n",
      "NLS score: 0.49642398829475076\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "weighted_accuracies = []\n",
    "\n",
    "for index, sample in enumerate(unpadded_gold_nls):\n",
    "    predicted_sample = unpadded_predicted_nls[index]\n",
    "    accuracies.append(accuracy_score(sample, predicted_sample))\n",
    "    precisions.append(precision_score(sample, predicted_sample, average='macro', zero_division=0))\n",
    "    recalls.append(recall_score(sample, predicted_sample, average='macro', zero_division=0))\n",
    "    f1s.append(f1_score(sample, predicted_sample, average='macro', zero_division=0))\n",
    "    \n",
    "    weighted_accuracy = 0\n",
    "    for word_index, word in enumerate(sample):\n",
    "        if word == NO_NLS_TOKEN:\n",
    "            weight = nls_ratio\n",
    "        else:\n",
    "            weight = 1 - nls_ratio\n",
    "        \n",
    "        weighted_accuracy += weight * (word == predicted_sample[word_index])\n",
    "    weighted_accuracies.append(weighted_accuracy / len(sample))\n",
    "\n",
    "\n",
    "\n",
    "print('Average accuracy:', sum(accuracies) / len(accuracies))\n",
    "print('Average precision:', sum(precisions) / len(precisions))\n",
    "print('Average recall:', sum(recalls) / len(recalls))\n",
    "print('Average f1:', sum(f1s) / len(f1s))\n",
    "print('Average weighted accuracy:', sum(weighted_accuracies) / len(weighted_accuracies))\n",
    "print('NLS score:', ((sum(weighted_accuracies) / len(weighted_accuracies)) + (sum(accuracies) / len(accuracies))) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average meteor score: 0.9719289290194459\n"
     ]
    }
   ],
   "source": [
    "meteor_scores = [single_meteor_score(gold_sentence, predicted_sentences[index]) for index, gold_sentence in enumerate(gold_sentences)]\n",
    "print('Average meteor score:', sum(meteor_scores) / len(meteor_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', 'well', 'thank', 'you', 'very', 'much', 'bye-bye', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "def generate_nls_sentence(sentence):\n",
    "    tokenized = [START_TOKEN, *nltk.word_tokenize(sentence), END_TOKEN]\n",
    "    tagged = nltk.pos_tag(tokenized[1:-1])\n",
    "    pos_tagged = [START_TOKEN, *[tag[1] for tag in tagged], END_TOKEN]\n",
    "\n",
    "    pos_encoded = torch.Tensor([train_dataloader.dataset.get_encoded_pos(pos) for pos in pos_tagged]).type(torch.LongTensor)\n",
    "    glove_encoded = torch.Tensor([glove_vectors.stoi[word] if word in glove_vocab else glove_vectors.stoi[UNKNOWN_TOKEN] for word in tokenized]).type(torch.LongTensor)\n",
    "    word_encoded = torch.Tensor([train_dataloader.dataset.get_encoded_word(word) for word in tokenized]).type(torch.LongTensor)\n",
    "    \n",
    "    return predict_nls(glove_encoded, pos_encoded, tokenized)\n",
    "\n",
    "sentence = 'well thank you very much bye-bye'\n",
    "print(generate_nls_sentence(sentence))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('non-lexical-sounds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04ba6b763ac396e36817db00c7c25b3b8b4e4d9f8d46e107c06cc536e1d19006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
